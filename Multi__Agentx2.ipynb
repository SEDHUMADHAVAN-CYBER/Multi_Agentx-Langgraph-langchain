{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR0xdb7aNIibO97zmLXo3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEDHUMADHAVAN-CYBER/Multi_Agentx-Langgraph-langchain/blob/main/Multi__Agentx2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio langgraph langchain-groq -q\n",
        "print(\"‚úÖ Gradio ready!\")\n"
      ],
      "metadata": {
        "id": "70nKAl0dfd-A",
        "outputId": "cf4dcdc2-d38e-481a-9818-65dc9126874a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m133.1/137.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/495.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m491.5/495.8 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m495.8/495.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Gradio ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from typing import TypedDict, List, Optional\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import random\n",
        "\n",
        "class AgentState(TypedDict, total=False):\n",
        "    user_input: str\n",
        "    plan: List[str]\n",
        "    collaborator_output: Optional[str]\n",
        "    competitor_output: Optional[str]\n",
        "    negotiated_output: Optional[str]\n",
        "    final_output: Optional[str]\n",
        "    reward_score: Optional[int]\n",
        "\n",
        "# LLM Setup\n",
        "llm = ChatGroq(\n",
        "    groq_api_key=userdata.get(\"GROQ_API_KEY\"),\n",
        "    model_name=\"llama-3.1-8b-instant\"\n",
        ")\n",
        "\n",
        "# Pure agent functions\n",
        "def planner_agent(state: AgentState) -> AgentState:\n",
        "    prompt = f\"Break this task into 3 clear steps:\\n{state['user_input']}\"\n",
        "    response = llm.invoke(prompt)\n",
        "    steps = [s.strip(\"- \").strip() for s in response.content.split(\"\\n\") if s.strip()]\n",
        "    if not steps: steps = [\"Analyze\", \"Explain\", \"Conclude\"]\n",
        "    return {\"plan\": steps[:3]}\n",
        "\n",
        "def collaborator_agent(state: AgentState) -> AgentState:\n",
        "    prompt = f\"Task: {state['user_input']}\\nPlan: {state['plan']}\\nProvide helpful, optimistic solution.\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"collaborator_output\": response.content}\n",
        "\n",
        "def competitor_agent(state: AgentState) -> AgentState:\n",
        "    prompt = f\"Task: {state['user_input']}\\nCritique collaborator. Different perspective.\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"competitor_output\": response.content}\n",
        "\n",
        "def negotiation_agent(state: AgentState) -> AgentState:\n",
        "    prompt = f\"Collaborator: {state['collaborator_output'][:1000]}\\nCompetitor: {state['competitor_output'][:1000]}\\nCombine into stronger answer.\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"negotiated_output\": response.content}\n",
        "\n",
        "def judge_agent(state: AgentState) -> AgentState:\n",
        "    prompt = f\"Task: {state['user_input']}\\nCollaborator: {state['collaborator_output'][:800]}\\nCompetitor: {state['competitor_output'][:800]}\\nDecide which is better.\"\n",
        "    response = llm.invoke(prompt)\n",
        "    score = random.randint(1, 10)\n",
        "    return {\"final_output\": response.content, \"reward_score\": score}\n",
        "\n",
        "# Build Graph\n",
        "from langgraph.graph import StateGraph, END\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"planner\", planner_agent)\n",
        "graph.add_node(\"collaborator\", collaborator_agent)\n",
        "graph.add_node(\"competitor\", competitor_agent)\n",
        "graph.add_node(\"negotiator\", negotiation_agent)\n",
        "graph.add_node(\"judge\", judge_agent)\n",
        "\n",
        "graph.set_entry_point(\"planner\")\n",
        "graph.add_edge(\"planner\", \"collaborator\")\n",
        "graph.add_edge(\"planner\", \"competitor\")\n",
        "graph.add_edge(\"collaborator\", \"negotiator\")\n",
        "graph.add_edge(\"competitor\", \"negotiator\")\n",
        "graph.add_edge(\"negotiator\", \"judge\")\n",
        "graph.add_edge(\"judge\", END)\n",
        "\n",
        "multi_agent_graph = graph.compile()\n",
        "\n",
        "# MAIN FUNCTION\n",
        "def run_multi_agent(question):\n",
        "    state = {\"user_input\": question}\n",
        "    final_state = multi_agent_graph.invoke(state)\n",
        "\n",
        "    # Format output\n",
        "    plan = \", \".join(final_state.get('plan', []))\n",
        "    collab = final_state.get('collaborator_output', 'N/A')[:500] + \"...\"\n",
        "    comp = final_state.get('competitor_output', 'N/A')[:500] + \"...\"\n",
        "    neg = final_state.get('negotiated_output', 'N/A')[:500] + \"...\"\n",
        "    judgment = final_state.get('final_output', 'N/A')\n",
        "    score = final_state.get('reward_score', 0)\n",
        "\n",
        "    return f\"\"\"\n",
        "ü§ñ **Multi-Agent Demo Results**\n",
        "\n",
        "**üß† Plan:** {plan}\n",
        "\n",
        "**ü§ù Collaborator:** {collab}\n",
        "**‚öîÔ∏è Competitor:** {comp}\n",
        "\n",
        "**üí¨ Negotiated:** {neg}\n",
        "\n",
        "**üèÜ Judgment:** {judgment}\n",
        "\n",
        "üéâ **Score: {score}/10** ‚≠ê‚≠ê‚≠ê\n",
        "    \"\"\"\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks(title=\"Multi-Agent Judge Demo\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# ü§ñ Multi-Agent Collaboration System\")\n",
        "    gr.Markdown(\"**Planner ‚Üí Collaborator vs Competitor ‚Üí Negotiator ‚Üí Judge**\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            input_box = gr.Textbox(\n",
        "                label=\"Ask the Multi-Agent Team\",\n",
        "                placeholder=\"What is machine learning?\",\n",
        "                lines=2\n",
        "            )\n",
        "        with gr.Column(scale=2):\n",
        "            run_btn = gr.Button(\"üöÄ Run Agents\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "    output = gr.Markdown(\"**Results appear here...**\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"What is machine learning?\",\n",
        "            \"Explain neural networks\",\n",
        "            \"How does blockchain work?\"\n",
        "        ],\n",
        "        inputs=input_box\n",
        "    )\n",
        "\n",
        "    run_btn.click(run_multi_agent, inputs=input_box, outputs=output)\n",
        "\n",
        "# LAUNCH PUBLICLY\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "ml0AbNFgfgd8",
        "outputId": "5238c484-aa7e-4eaf-b898-3560736e5b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1888275100.py:99: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(title=\"Multi-Agent Judge Demo\", theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5ed6fb4aead4e43fab.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5ed6fb4aead4e43fab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}